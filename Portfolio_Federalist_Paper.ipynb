{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Jesse Truong, JTT190006, 11/12/2022"
      ],
      "metadata": {
        "id": "Fyg_eAfFhfzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "!pip install \"scikit_learn==0.22.2.post1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "ZfqbOuTMx5Tu",
        "outputId": "572d78be-11d5-46e8-9fbb-1e225529b8fa"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit_learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.22.2.post1) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.22.2.post1) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.22.2.post1) (1.7.3)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.22.2.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "PQ3lMyNtbwtT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes  import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model.logistic import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('federalist.csv')"
      ],
      "metadata": {
        "id": "WULmpow0sCt1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'] = df.author.astype('category')\n",
        "print(df.head())\n",
        "print()\n",
        "print(df.groupby(['author']).count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "paRczR--sOGz",
        "outputId": "4558b955-eff0-4f1f-ffd4-29c6c0ce01d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     author                                               text\n",
            "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
            "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
            "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
            "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
            "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C...\n",
            "\n",
            "                      text\n",
            "author                    \n",
            "HAMILTON                49\n",
            "HAMILTON AND MADISON     3\n",
            "HAMILTON OR MADISON     11\n",
            "JAY                      5\n",
            "MADISON                 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['author'], test_size=0.2, random_state=1234) # Getting the training/testing split\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pAZfISXZt5B4",
        "outputId": "041e711a-3780-4ea1-cd88-f2959652f391"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66,)\n",
            "(17,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(stop_words=stoplist,)\n",
        "X_train = vectorizer.fit_transform(X_train)  # fit and transform the train data\n",
        "X_test = vectorizer.transform(X_test)        # transform only the test data"
      ],
      "metadata": {
        "id": "4kfm3hrWyrVE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Sp2QhhSpwL3_",
        "outputId": "198a9e30-15be-4d55-c4ea-1ef000f946d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66, 7876)\n",
            "(17, 7876)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train, y_train) # Bernulli Navie Bayes model training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UsTjU03p0naG",
        "outputId": "a7895670-7af8-49ff-a309-181073aa7a53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# make predictions on the test data\n",
        "pred1 = bnb.predict(X_test)\n",
        "print('accuracy score: ', accuracy_score(y_test, pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RGeR161z75wg",
        "outputId": "62c0c70a-c862-40e5-d022-efda20be8cd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.5882352941176471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2UNbutJ8CoO"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdf = TfidfVectorizer(stop_words=stoplist, max_features= 1000, ngram_range = (1,2)) # Removing stopwords, limiting features, and adding bi gramns\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(df['text'], df['author'], test_size=0.2, random_state=1234)\n",
        "X2_train = tdf.fit_transform(X2_train)  \n",
        "X2_test = tdf.transform(X2_test)\n",
        "\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X2_train, y2_train) # Bernoulli Navies Bayes Model traning\n",
        "\n",
        "pred2 = bnb.predict(X2_test)\n",
        "print('accuracy score: ', accuracy_score(y2_test, pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WD6KvspL8Cj-",
        "outputId": "20b33d9a-dcf4-4b02-838d-e557fe3bf661"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.9411764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy score: ', accuracy_score(y_test, pred1))\n",
        "print('accuracy score: ', accuracy_score(y2_test, pred2)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4I4VbkAaOgmU",
        "outputId": "7848b34f-07ad-4f93-efbb-1c5368b54c23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.5882352941176471\n",
            "accuracy score:  0.9411764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['author'], test_size=0.2, random_state=1234) "
      ],
      "metadata": {
        "id": "zWiXmcQscGh5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipe1 = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('logreg', LogisticRegression(multi_class='multinomial',solver='saga',class_weight='balanced', penalty = 'l2')),\n",
        "]) # Pipeline for logistic Regression with multi classing\n",
        "pipe1.fit(X_train,y_train) # Logistic Regression Training\n",
        "pred3 = pipe1.predict(X_test)\n",
        "import numpy as np\n",
        "print(\"\\nOverall accuracy: \", np.mean(pred3==y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ebGQGWRCQgNU",
        "outputId": "39cc678a-de3f-4d91-cddf-0fb75f6c168b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall accuracy:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe2 = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('neuralnet', MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                   hidden_layer_sizes=(50, 10), random_state=1234)),\n",
        "         ]) # Pipeline for Neural Network \n",
        "\n",
        "pipe2.fit(X_train, y_train) # NN training\n",
        "pred4 = pipe2.predict(X_test)\n",
        "print(\"\\nOverall accuracy: \", np.mean(pred4==y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-tqMJrdnaN_W",
        "outputId": "91e8df91-7748-4973-a325-8cf50a3a07c3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall accuracy:  0.8823529411764706\n"
          ]
        }
      ]
    }
  ]
}